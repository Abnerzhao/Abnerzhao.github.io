<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title> 豆瓣房源爬虫小记 · Abnerzhao</title><meta name="description" content="豆瓣房源爬虫小记 - Abnerzhao"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="icon" href="/favicon.png"><link rel="stylesheet" href="/css/apollo.css"><link rel="search" type="application/opensearchdescription+xml" href="http://yoursite.com/atom.xml" title="Abnerzhao"></head><body><div class="wrap"><header><a href="/" class="logo-link"><img src="/favicon.png" alt="logo"></a><ul class="nav nav-list"><li class="nav-list-item"><a href="/" target="_self" class="nav-list-link">BLOG</a></li><li class="nav-list-item"><a href="/archives/" target="_self" class="nav-list-link">ARCHIVE</a></li><li class="nav-list-item"><a href="https://github.com/abnerzhao" target="_blank" class="nav-list-link">GITHUB</a></li><li class="nav-list-item"><a href="/about/" target="_self" class="nav-list-link">ABOUT</a></li></ul></header><main class="container"><div class="post"><article class="post-block"><h1 class="post-title">豆瓣房源爬虫小记</h1><div class="post-info">Apr 5, 2018</div><div class="post-content"><p>最近又要开始找房，来上海三年不到已经是第三次搬家，真是居大不易。现在住的房子是在豆瓣小组上找的，豆瓣上个人房源较多，但是豆瓣小组没有对房源信息进行分类，找起来比较费时，索性写了个简单的爬虫，根据关键字来找房。网上也有一些现成的代码实现，想着还是自己实践一下。</p>
<p>Python 新手上路…</p>
<h3 id="获取豆瓣房源小组链接"><a href="#获取豆瓣房源小组链接" class="headerlink" title="获取豆瓣房源小组链接"></a>获取豆瓣房源小组链接</h3><p>先搜索一下上海的租房小组</p>
<p><img src="/img/270B4257-2781-4F04-A000001F-A539B7F1791D.png" alt=""></p>
<p>找几个人数较多和活跃度高的小组，进入小组讨论页面，观察 URL 的规律。<br><a id="more"></a><br><img src="/img/1D40CBE0-36C5-45E4-9B42-0E7823ADF269.png" alt=""><br><img src="/img/7BD30596-ABF6-428C-BF7B-D232B1C6605D.png" alt=""></p>
<p>由此可知我们可以通过 <code>https://www.douban.com/group/&lt;组名&gt;/disscussion</code> 来获取不同组的房源帖子信息，我选取了五个小组进行爬取。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">In [1]: import os</div><div class="line">In [2]: group_list = [&apos;shanghaizufang&apos;, &apos;homeatshanghai&apos;, &apos;383972&apos;, &apos;shzf&apos;, &apos;251101&apos;]</div><div class="line">In [3]: index_url = [os.path.join(&apos;https://www.douban.com/group&apos;, i, &apos;discussion&apos;) for i in group_list]</div><div class="line">In [4]: index_url</div><div class="line">Out[4]:</div><div class="line">[&apos;https://www.douban.com/group/shanghaizufang/discussion&apos;,</div><div class="line"> &apos;https://www.douban.com/group/homeatshanghai/discussion&apos;,</div><div class="line"> &apos;https://www.douban.com/group/383972/discussion&apos;,</div><div class="line"> &apos;https://www.douban.com/group/shzf/discussion&apos;,</div><div class="line"> &apos;https://www.douban.com/group/251101/discussion&apos;]</div></pre></td></tr></table></figure>
<h3 id="资源定位"><a href="#资源定位" class="headerlink" title="资源定位"></a>资源定位</h3><p>通过查看页面元素信息，找到每个帖子标题所对应的网页代码。我们可以发现每个房源标题对应的是一个 <code>class</code> 属性为 <code>title</code> 的 <code>td</code> 标记。</p>
<p><img src="/img/59E824C2-AC6A-45F4-86D4-2582065E92A5.png" alt=""></p>
<p>使用 <code>BeautifulSoup</code> 尝试获取一下小组讨论中帖子标题网页代码</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">In [1]: import requests</div><div class="line">In [2]: from bs4 import BeautifulSoup</div><div class="line">In [3]: url = &apos;https://www.douban.com/group/shanghaizufang/discussion&apos;</div><div class="line">In [4]: headers = &#123;&apos;User-Agent&apos;: &apos;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_2) AppleWebKit/537.36 &apos;</div><div class="line">   ...:                                  &apos;(KHTML, like Gecko) Chrome/47.0.2526.80 Safari/537.36&apos;&#125;</div><div class="line">In [5]: res = requests.get(url, headers=headers)</div><div class="line">In [6]: soup = BeautifulSoup(res.text, &apos;html.parser&apos;)</div><div class="line">In [7]: title_list = soup.find_all(&apos;td&apos;, class_=&apos;title&apos;)</div><div class="line">In [8]: for tl in title_list:</div><div class="line">    ...:     print(tl)</div><div class="line">    ...:</div><div class="line">&lt;td class=&quot;title&quot;&gt;</div><div class="line">&lt;a class=&quot;&quot; href=&quot;https://www.douban.com/group/topic/114471599/&quot; title=&quot;黄浦区临地铁4号13号线单间出租。2300！无中介，可月租！&quot;&gt;</div><div class="line">                       黄浦区临地铁4号13号线单间出租。2300！无中介，可...</div><div class="line">                    &lt;/a&gt;</div><div class="line">&lt;/td&gt;</div><div class="line">&lt;td class=&quot;title&quot;&gt;</div><div class="line">&lt;a class=&quot;&quot; href=&quot;https://www.douban.com/group/topic/113810667/&quot; title=&quot;——有阳台·房间空间大·低价出租·2260元·正南·电梯房·步行6分钟到7号线·《盒马生鲜·DFC影院·大华锦绣国际》隔壁·锦绣华城2街区&quot;&gt;</div><div class="line">                       ——有阳台·房间空间大·低价出租·2260元·正南...</div><div class="line">                    &lt;/a&gt;</div><div class="line">&lt;/td&gt;</div><div class="line">&lt;td class=&quot;title&quot;&gt;</div><div class="line">&lt;a class=&quot;&quot; href=&quot;https://www.douban.com/group/topic/111282163/&quot; title=&quot;7号线杨高南路___北艾路1200弄超大1室_正南_大飘窗_2790元&quot;&gt;</div><div class="line">                       7号线杨高南路___北艾路1200弄超大1室_正南_大飘窗...</div><div class="line">                    &lt;/a&gt;</div><div class="line">&lt;/td&gt;</div><div class="line">...</div></pre></td></tr></table></figure>
<h3 id="关键字过滤"><a href="#关键字过滤" class="headerlink" title="关键字过滤"></a>关键字过滤</h3><p>通过 <code>BeautifulSoup</code> 我们已经成功获取到帖子标题相关网页代码信息，接下来就是匹配我们的关键字并把对应标题的 url 保存下来，这样我们就不用一页页去找房源信息。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">In [9]: for tl in title_list:</div><div class="line">    ...:     print(tl.a[&apos;title&apos;], tl.a[&apos;href&apos;])</div><div class="line">    ...:</div><div class="line">紧靠漕河泾地铁12号线虹梅路站古美小区精装一室户随时看房 https://www.douban.com/group/topic/114690388/</div><div class="line">【性价比最高】【2/4/6/9】世纪大道地铁站口200米内，2018.4.5起三天内【出租】有效 https://www.douban.com/group/topic/114031302/</div><div class="line">陆家嘴，2号线东昌路站，精装南北两房一厅，5400元可谈，乳山四村 https://www.douban.com/group/topic/114838496/</div><div class="line">7号线30秒___高科西路2111弄（独立阳台_洗漱）2890 https://www.douban.com/group/topic/111749919/</div><div class="line">1号线外环路站______主卧朝南、近地铁 https://www.douban.com/group/topic/115006334/</div><div class="line">7号线__成山路2388弄(高档小区）__环境美_2090元 https://www.douban.com/group/topic/111343989/</div><div class="line">1500元就能租到社区一居室/复式低价火热出租ING https://www.douban.com/group/topic/114031502/</div><div class="line">1号线❤️莲花路站❤️朝南+落地窗（4分钟到地铁）___2200¥ https://www.douban.com/group/topic/115010633/</div><div class="line">工作调动2469号线德平路地铁站两房！价格可刀 https://www.douban.com/group/topic/114668639/</div><div class="line">2号线 淞虹路站 通协小区 朝南主卧带飘窗 随时入住 精装全配 可做饭 凌空首选随时入住先到先得 2700/月 https://www.douban.com/group/topic/114638949/</div><div class="line">3号线铁力路站，实体墙一室带独立卫生间，可以做饭，出租1900元。 https://www.douban.com/group/topic/115000070/</div><div class="line">1号线莲花路站_____步行2分钟（西班牙名园小区） https://www.douban.com/group/topic/115009200/</div><div class="line">—落地大阳台·2780元·豪装—海归首选房—敞亮的大房子《陆家嘴·锦绣里》高档小区—电梯房 https://www.douban.com/group/topic/113808306/</div><div class="line">静安高荣小区朝南带阳台主卧出租&lt;限女生&gt;3100/月，直接和房东签合同 https://www.douban.com/group/topic/114799989/</div><div class="line">1号线❤️外环路站【主卧独卫】地铁口__ 上海阳城小区 https://www.douban.com/group/topic/115008659/</div><div class="line">五角场附近主卧出租，市光路70弄小区，限女生 https://www.douban.com/group/topic/113345605/</div><div class="line">7号线_北艾路1200弄__正南温馨_干净安静：1690元（租女生） https://www.douban.com/group/topic/112014980/</div><div class="line">7号线锦绣路站【山姆会员店】旁边  朝南精装大1室 带飘窗__2490元 https://www.douban.com/group/topic/111243092/</div><div class="line">一三四八号线上海火车站附近 （2400）限一个女生 （实图个图）有厨房 朝南主卧 https://www.douban.com/group/topic/114856540/</div><div class="line">一室一厅一厨一卫整租！7号线，上海大学地铁站！6分钟！ https://www.douban.com/group/topic/114814137/</div><div class="line">【无中介】2号线 中山公园和8号线翔殷路（靠近10号线五角广场）及9号线松江大学城站一室户 https://www.douban.com/group/topic/114031377/</div><div class="line">七号线南陈路，整租两房两厅，便宜出租！ https://www.douban.com/group/topic/113826619/</div><div class="line">7号线__北艾路1200弄__超大一室，非常温馨：2490元 https://www.douban.com/group/topic/112276783/</div><div class="line">2/4/6/9号线世纪大道站，精装双南两房一厅，6600元可谈，梅园五街坊 https://www.douban.com/group/topic/114883174/</div><div class="line">这应该是徐家汇最好的公寓 https://www.douban.com/group/topic/113839494/</div><div class="line"></div><div class="line">In [10]: keyword = &apos;1号线&apos;</div><div class="line">In [11]: for tl in title_list:</div><div class="line">    ...:     if keyword in tl.a[&apos;title&apos;]:</div><div class="line">    ...:         print(tl.a[&apos;title&apos;], tl.a[&apos;href&apos;])</div><div class="line">    ...:</div><div class="line">1号线外环路站______主卧朝南、近地铁 https://www.douban.com/group/topic/115006334/</div><div class="line">1号线❤️莲花路站❤️朝南+落地窗（4分钟到地铁）___2200¥ https://www.douban.com/group/topic/115010633/</div><div class="line">1号线莲花路站_____步行2分钟（西班牙名园小区） https://www.douban.com/group/topic/115009200/</div><div class="line">1号线❤️外环路站【主卧独卫】地铁口__ 上海阳城小区 https://www.douban.com/group/topic/115008659/</div></pre></td></tr></table></figure>
<h3 id="页码控制"><a href="#页码控制" class="headerlink" title="页码控制"></a>页码控制</h3><p>以上海租房小组为例，之前测试爬取的路径是 <code>https://www.douban.com/group/shanghaizufang/discussion</code> 默认只会爬取第一页的 25 条信息，那么我们想爬取更多的信息，如何控制爬取的页码呢？</p>
<p><img src="http://7vzmp5.com1.z0.glb.clouddn.com/40E19CBD-E356-4CFA-B635-A430631C84D0.png" alt=""></p>
<p>通过　<code>class</code> 属性为 <code>next</code> 的 <code>span</code>　标记可以获取到下一页的链接地址，<code>https://www.douban.com/group/shanghaizufang/discussion?start=25</code> 表示第二页从第 25 条记录开始展示，我们可以通过这个控制要爬取的信息条数。</p>
<h3 id="代码概览"><a href="#代码概览" class="headerlink" title="代码概览"></a>代码概览</h3><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line"># -*- coding:utf-8 -*-</div><div class="line"></div><div class="line">import os</div><div class="line">import requests</div><div class="line">import time</div><div class="line">from bs4 import BeautifulSoup</div><div class="line"></div><div class="line"></div><div class="line">class DouBanHouseSpider(object):</div><div class="line"></div><div class="line">    &quot;&quot;&quot;</div><div class="line">    抓取豆瓣小组房源信息</div><div class="line"></div><div class="line">     Attributes:</div><div class="line">        key_word: 房源标题关键字</div><div class="line">        page_num: 每个小组的抓取页数</div><div class="line">        group_list: 豆瓣小组列表</div><div class="line">        index_url: 豆瓣小组列表链接</div><div class="line">        data: 存放抓取结果</div><div class="line">    &quot;&quot;&quot;</div><div class="line">    def __init__(self, key_word, page_num):</div><div class="line">        self.key_word = key_word</div><div class="line">        self.page_num = page_num</div><div class="line">        self.group_list = [&apos;shanghaizufang&apos;, &apos;homeatshanghai&apos;, &apos;383972&apos;, &apos;shzf&apos;, &apos;251101&apos;]</div><div class="line">        self.index_url = [os.path.join(&apos;https://www.douban.com/group&apos;, i, &apos;discussion&apos;) for i in self.group_list]</div><div class="line">        self.data = &#123;&#125;</div><div class="line">        print(&apos;豆瓣房源爬虫准备就绪, 开始爬取数据...&apos;)</div><div class="line"></div><div class="line">    def get_url_content(self, url):</div><div class="line">        &quot;&quot;&quot;</div><div class="line">        根据 url 抓取页面数据</div><div class="line"></div><div class="line">        Args:</div><div class="line">            url: 豆瓣小组链接</div><div class="line">        &quot;&quot;&quot;</div><div class="line">        try:</div><div class="line">            time.sleep(1)</div><div class="line">            headers = &#123;&apos;User-Agent&apos;: &apos;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_2) AppleWebKit/537.36 &apos;</div><div class="line">                                     &apos;(KHTML, like Gecko) Chrome/47.0.2526.80 Safari/537.36&apos;&#125;</div><div class="line">            res = requests.get(url, headers=headers)</div><div class="line">            soup = BeautifulSoup(res.text, &apos;html.parser&apos;)</div><div class="line">            title_list = soup(&apos;td&apos;, class_=&apos;title&apos;)</div><div class="line">            for tl in title_list:</div><div class="line">                if self.key_word in tl.a.attrs[&apos;title&apos;]:</div><div class="line">                    self.data[tl.a.attrs[&apos;title&apos;]] = tl.a.attrs[&apos;href&apos;]</div><div class="line">            next_page = soup(&apos;span&apos;, class_=&apos;next&apos;)</div><div class="line">            if next_page:</div><div class="line">                next_url = next_page[0].link.attrs[&apos;href&apos;]</div><div class="line">                end_title = next_url.split(&apos;=&apos;)[1]</div><div class="line">                if int(end_title) &lt; (self.page_num * 25):</div><div class="line">                    self.get_url_content(next_url)</div><div class="line">        except Exception as e:</div><div class="line">            print(&apos;抓取过程报错：%s&apos; % e)</div><div class="line"></div><div class="line">    def start_spider(self):</div><div class="line">        &quot;&quot;&quot;</div><div class="line">        爬虫入口</div><div class="line">        &quot;&quot;&quot;</div><div class="line">        for i in self.index_url:</div><div class="line">            self.get_url_content(i)</div><div class="line">        for k, v in self.data.items():</div><div class="line">            print(&apos;标题：%s, 链接地址：%s&apos;%(k,v))</div><div class="line"></div><div class="line"></div><div class="line">def main():</div><div class="line">    &quot;&quot;&quot;</div><div class="line">    主函数</div><div class="line">    &quot;&quot;&quot;</div><div class="line">    print(&quot;&quot;&quot;</div><div class="line">            ###############################</div><div class="line">                豆瓣房源小组爬虫</div><div class="line">                Author: Abnerzhao</div><div class="line">                Version: 0.0.1</div><div class="line">                Date: 2018-04-04</div><div class="line">            ###############################</div><div class="line">        &quot;&quot;&quot;)</div><div class="line">    key_word = input(&apos;请输入找房关键字：&apos;)</div><div class="line">    page_num = input(&apos;请输入抓取页面数：&apos;)</div><div class="line">    if not key_word:</div><div class="line">        key_word = &apos;1号线&apos;</div><div class="line">    if not page_num:</div><div class="line">        page_num = 5</div><div class="line">    house_spider = DouBanHouseSpider(key_word, int(page_num))</div><div class="line">    house_spider.start_spider()</div><div class="line">    print(&apos;豆瓣房源爬虫爬取结束...&apos;)</div><div class="line"></div><div class="line"></div><div class="line">if __name__ == &apos;__main__&apos;:</div><div class="line">    main()</div></pre></td></tr></table></figure>
<blockquote>
<p>请使用 Python3，<a href="https://github.com/Abnerzhao/spider/blob/master/douban/douban_spider_exp1.py" target="_blank" rel="external">爬虫源码地址</a></p>
</blockquote>
<p>执行效果：</p>
<p><img src="/img/BAFCA92D-6F56-478A-B94E-8D18830BB546.png" alt=""></p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>这个爬虫很简单，没有进行模拟登陆也能抓取，当抓取页面数较大时会耗时较长。同一个房源信息可能在不同的小组中都有，所以通过一个字典来保存抓取的标题和链接，避免重复的标题。</p>
<p>后续待优化的地方:</p>
<ul>
<li>模拟登陆</li>
<li>支持多个关键字</li>
<li>多线程</li>
</ul>
</div></article></div></main><footer><div class="paginator"><a href="/2018/08/19/QuerySet-API-学习笔记/" class="prev">PREV</a><a href="/2018/03/25/celery-background/" class="next">NEXT</a></div><div class="copyright"><p>© 2017 - 2020 <a href="http://yoursite.com">Abnerzhao</a>, powered by <a href="https://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/pinggod/hexo-theme-apollo" target="_blank">hexo-theme-apollo</a>.</p></div></footer></div><script async src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML" integrity="sha384-crwIf/BuaWM9rM65iM+dWFldgQ1Un8jWZMuh3puxb8TOY9+linwLoI7ZHZT+aekW" crossorigin="anonymous"></script><script>(function(b,o,i,l,e,r){b.GoogleAnalyticsObject=l;b[l]||(b[l]=function(){(b[l].q=b[l].q||[]).push(arguments)});b[l].l=+new Date;e=o.createElement(i);r=o.getElementsByTagName(i)[0];e.src='//www.google-analytics.com/analytics.js';r.parentNode.insertBefore(e,r)}(window,document,'script','ga'));ga('create',"UA-65933410-1",'auto');ga('send','pageview');</script></body></html>